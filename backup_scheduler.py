# backup_scheduler.py - Backup vers GitHub Releases - VERSION CORRIGÃ‰E
import os
import sqlite3
import schedule
import time
import logging
import json
import zipfile
import threading
import requests
from datetime import datetime, timedelta
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GitHubBackupManager:
    """Gestionnaire de sauvegardes automatiques vers GitHub Releases - VERSION CORRIGÃ‰E"""
    
    def __init__(self):
        self.config = {
            'db_path': os.environ.get('DB_PATH', '/opt/render/project/data/erp_production_dg.db'),
            'backup_local_dir': os.environ.get('BACKUP_LOCAL_DIR', '/opt/render/project/data/backups'),
            
            # Configuration GitHub
            'github_enabled': os.environ.get('GITHUB_BACKUP_ENABLED', 'true').lower() == 'true',
            'github_token': os.environ.get('GITHUB_TOKEN'),
            'github_repo': os.environ.get('GITHUB_REPO', 'Estimation79/gestion-projets-dg'),
            'github_api_url': 'https://api.github.com',
            
            'keep_local_backups': int(os.environ.get('KEEP_LOCAL_BACKUPS', '5')),
            'keep_github_releases': int(os.environ.get('KEEP_GITHUB_RELEASES', '10')),
            'max_backup_size_mb': int(os.environ.get('MAX_BACKUP_SIZE_MB', '100')),
            
            # NOUVELLES VARIABLES DEBUG CORRIGÃ‰ES
            'backup_schedule_minutes': int(os.environ.get('BACKUP_SCHEDULE_MINUTES', '120')),
            'immediate_backup_test': os.environ.get('IMMEDIATE_BACKUP_TEST', 'false').lower() == 'true',
            'force_backup_on_start': os.environ.get('FORCE_BACKUP_ON_START', 'false').lower() == 'true',
            'debug_github_backup': os.environ.get('DEBUG_GITHUB_BACKUP', 'false').lower() == 'true'
        }
        
        Path(self.config['backup_local_dir']).mkdir(parents=True, exist_ok=True)
        self._validate_github_config()
        
        # NOUVEAU : Logging debug activÃ©
        if self.config['debug_github_backup']:
            logging.getLogger().setLevel(logging.DEBUG)
            logger.debug("ğŸ” Mode DEBUG backup activÃ©")
    
    def _validate_github_config(self):
        """Valide la configuration GitHub - VERSION AMÃ‰LIORÃ‰E"""
        if not self.config['github_enabled']:
            logger.info("ğŸ“Š Backup GitHub dÃ©sactivÃ©")
            return
        
        if not self.config['github_token']:
            logger.error("âŒ GITHUB_TOKEN manquant")
            self.config['github_enabled'] = False
            return
        
        # AMÃ‰LIORATION : Test de connexion plus robuste
        try:
            headers = {'Authorization': f'token {self.config["github_token"]}'}
            
            # Test 1 : VÃ©rifier l'accÃ¨s au repo
            repo_response = requests.get(
                f"{self.config['github_api_url']}/repos/{self.config['github_repo']}", 
                headers=headers, timeout=10
            )
            
            if repo_response.status_code == 200:
                repo_info = repo_response.json()
                logger.info(f"âœ… Repo GitHub accessible: {repo_info['full_name']}")
                
                # Test 2 : VÃ©rifier les permissions releases
                releases_response = requests.get(
                    f"{self.config['github_api_url']}/repos/{self.config['github_repo']}/releases",
                    headers=headers, timeout=10
                )
                
                if releases_response.status_code == 200:
                    logger.info("âœ… Permissions releases OK")
                    return True
                else:
                    logger.error(f"âŒ Pas d'accÃ¨s aux releases: {releases_response.status_code}")
                    
            else:
                logger.error(f"âŒ Erreur accÃ¨s repo: {repo_response.status_code}")
                
        except Exception as e:
            logger.error(f"âŒ Erreur connexion GitHub: {e}")
        
        self.config['github_enabled'] = False
        return False
    
    def create_backup(self):
        """CrÃ©e une sauvegarde de la base de donnÃ©es - AVEC DEBUG"""
        try:
            logger.info("ğŸš€ DÃ‰BUT crÃ©ation backup")
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_name = f"erp_dg_backup_{timestamp}"
            
            if not os.path.exists(self.config['db_path']):
                logger.error(f"âŒ Base de donnÃ©es non trouvÃ©e: {self.config['db_path']}")
                return None
            
            # AMÃ‰LIORATION : VÃ©rification taille DB
            db_size_mb = os.path.getsize(self.config['db_path']) / (1024*1024)
            logger.info(f"ğŸ“Š Taille DB Ã  sauvegarder: {db_size_mb:.2f} MB")
            
            # Sauvegarde SQLite
            backup_db_path = os.path.join(self.config['backup_local_dir'], f"{backup_name}.db")
            logger.debug(f"ğŸ“ Chemin backup DB: {backup_db_path}")
            
            source_conn = sqlite3.connect(self.config['db_path'])
            backup_conn = sqlite3.connect(backup_db_path)
            
            with backup_conn:
                source_conn.backup(backup_conn)
            
            source_conn.close()
            backup_conn.close()
            logger.info("âœ… Backup SQLite terminÃ©")
            
            # MÃ©tadonnÃ©es dÃ©taillÃ©es
            stats = self._get_database_stats(backup_db_path)
            metadata = {
                'backup_time': datetime.now().isoformat(),
                'backup_time_readable': datetime.now().strftime('%d/%m/%Y Ã  %H:%M:%S'),
                'backup_size_mb': round(os.path.getsize(backup_db_path) / (1024*1024), 2),
                'company': 'Desmarais & GagnÃ© Inc.',
                'database_stats': stats,
                'github_repo': self.config['github_repo'],
                'render_info': {
                    'service_id': os.environ.get('RENDER_SERVICE_ID', 'unknown'),
                    'git_commit': os.environ.get('RENDER_GIT_COMMIT', 'unknown')[:8],
                    'deploy_id': os.environ.get('RENDER_DEPLOY_ID', 'unknown')
                }
            }
            
            metadata_path = os.path.join(self.config['backup_local_dir'], f"{backup_name}.json")
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # Compression optimisÃ©e
            zip_path = os.path.join(self.config['backup_local_dir'], f"{backup_name}.zip")
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=9) as zipf:
                zipf.write(backup_db_path, f"{backup_name}.db")
                zipf.write(metadata_path, f"{backup_name}_info.json")
                
                # Ajouter un README dans le ZIP
                readme_content = self._create_backup_readme(metadata)
                zipf.writestr("README_BACKUP.md", readme_content)
            
            # Nettoyage fichiers temporaires
            os.remove(backup_db_path)
            os.remove(metadata_path)
            
            final_size_mb = round(os.path.getsize(zip_path) / (1024*1024), 2)
            logger.info(f"âœ… Backup ZIP crÃ©Ã©: {final_size_mb} MB")
            logger.info(f"ğŸ“ Chemin final: {zip_path}")
            
            return zip_path
            
        except Exception as e:
            logger.error(f"âŒ Erreur crÃ©ation sauvegarde: {e}")
            import traceback
            logger.error(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
            return None
    
    def _get_database_stats(self, db_path):
        """RÃ©cupÃ¨re les statistiques complÃ¨tes de la base"""
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            stats = {}
            tables = ['projects', 'companies', 'employees', 'formulaires', 'work_centers', 
                     'operations', 'materials', 'time_entries', 'contacts', 'interactions']
            
            for table in tables:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    stats[table] = cursor.fetchone()[0]
                except:
                    stats[table] = 0
            
            # Statistiques additionnelles
            try:
                cursor.execute("SELECT COUNT(*) FROM projects WHERE statut = 'EN COURS'")
                stats['projects_active'] = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM projects WHERE statut = 'TERMINÃ‰'")
                stats['projects_completed'] = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM time_entries WHERE DATE(start_time) = DATE('now')")
                stats['timetracker_today'] = cursor.fetchone()[0]
                
            except:
                pass
            
            stats['total_records'] = sum(v for k, v in stats.items() if not k.startswith('projects_') and k != 'timetracker_today')
            conn.close()
            
            logger.debug(f"ğŸ“Š Stats DB: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"Erreur stats DB: {e}")
            return {}
    
    def _create_backup_readme(self, metadata):
        """CrÃ©e un README pour le backup"""
        stats = metadata.get('database_stats', {})
        return f"""# ğŸ­ ERP Production DG Inc. - Sauvegarde

## ğŸ“‹ Informations GÃ©nÃ©rales
- **Entreprise:** {metadata['company']}
- **Date de sauvegarde:** {metadata['backup_time_readable']}
- **Taille:** {metadata['backup_size_mb']} MB
- **Repository:** {metadata['github_repo']}

## ğŸ“Š Contenu de la Base de DonnÃ©es
- **Projets:** {stats.get('projects', 0)} (dont {stats.get('projects_active', 0)} actifs)
- **Entreprises/Clients:** {stats.get('companies', 0)}
- **EmployÃ©s:** {stats.get('employees', 0)}
- **Formulaires:** {stats.get('formulaires', 0)}
- **Postes de Travail:** {stats.get('work_centers', 0)}
- **OpÃ©rations:** {stats.get('operations', 0)}
- **MatÃ©riaux:** {stats.get('materials', 0)}
- **Pointages:** {stats.get('time_entries', 0)}
- **Contacts:** {stats.get('contacts', 0)}

**Total des enregistrements:** {stats.get('total_records', 0):,}

## ğŸ”§ Informations Techniques
- **Service Render:** {metadata.get('render_info', {}).get('service_id', 'N/A')}
- **Commit Git:** {metadata.get('render_info', {}).get('git_commit', 'N/A')}
- **Deploy ID:** {metadata.get('render_info', {}).get('deploy_id', 'N/A')}

## ğŸ“ Fichiers inclus
- `erp_dg_backup_YYYYMMDD_HHMMSS.db` - Base de donnÃ©es SQLite complÃ¨te
- `erp_dg_backup_YYYYMMDD_HHMMSS_info.json` - MÃ©tadonnÃ©es dÃ©taillÃ©es
- `README_BACKUP.md` - Cette documentation

## ğŸ”„ Restauration
Pour restaurer cette sauvegarde :
1. Extraire le fichier ZIP
2. Remplacer le fichier `erp_production_dg.db` par le fichier de backup
3. RedÃ©marrer l'application ERP

---
ğŸ¤– Sauvegarde automatique gÃ©nÃ©rÃ©e par le systÃ¨me ERP DG Inc.
"""
    
    def upload_to_github(self, backup_path):
        """Upload la sauvegarde vers GitHub Releases - VERSION CORRIGÃ‰E"""
        if not self.config['github_enabled']:
            logger.warning("ğŸ“Š Upload GitHub dÃ©sactivÃ©")
            return False
        
        try:
            logger.info("ğŸš€ DÃ‰BUT upload GitHub")
            
            file_size_mb = os.path.getsize(backup_path) / (1024 * 1024)
            logger.info(f"ğŸ“Š Taille fichier Ã  uploader: {file_size_mb:.2f} MB")
            
            if file_size_mb > self.config['max_backup_size_mb']:
                logger.error(f"ğŸ“ Fichier trop volumineux ({file_size_mb:.1f}MB > {self.config['max_backup_size_mb']}MB)")
                return False
            
            backup_filename = os.path.basename(backup_path)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # 1. CrÃ©er une release
            release_data = {
                'tag_name': f'backup-{timestamp}',
                'name': f'ğŸ­ ERP Backup - {datetime.now().strftime("%d/%m/%Y %H:%M")}',
                'body': self._create_release_description(backup_path),
                'draft': False,
                'prerelease': True
            }
            
            headers = {
                'Authorization': f'token {self.config["github_token"]}',
                'Content-Type': 'application/json'
            }
            
            logger.info("ğŸ“¦ CrÃ©ation de la release GitHub...")
            logger.debug(f"ğŸ”§ URL: {self.config['github_api_url']}/repos/{self.config['github_repo']}/releases")
            logger.debug(f"ğŸ”§ Headers: {headers}")
            logger.debug(f"ğŸ”§ Data: {release_data}")
            
            release_response = requests.post(
                f"{self.config['github_api_url']}/repos/{self.config['github_repo']}/releases",
                headers=headers,
                json=release_data,
                timeout=30
            )
            
            logger.info(f"ğŸ“‹ Response status: {release_response.status_code}")
            
            if release_response.status_code != 201:
                logger.error(f"âŒ Erreur crÃ©ation release: {release_response.status_code}")
                logger.error(f"ğŸ“‹ Response body: {release_response.text}")
                return False
            
            release_info = release_response.json()
            upload_url = release_info['upload_url'].replace('{?name,label}', '')
            logger.info(f"âœ… Release crÃ©Ã©e: {release_info['html_url']}")
            
            # 2. Upload du fichier
            logger.info("ğŸ“¤ Upload du fichier backup...")
            
            with open(backup_path, 'rb') as f:
                upload_headers = {
                    'Authorization': f'token {self.config["github_token"]}',
                    'Content-Type': 'application/zip'
                }
                
                logger.debug(f"ğŸ”§ Upload URL: {upload_url}?name={backup_filename}")
                
                upload_response = requests.post(
                    f"{upload_url}?name={backup_filename}&label=ERP Database Backup",
                    headers=upload_headers,
                    data=f,
                    timeout=120
                )
            
            logger.info(f"ğŸ“‹ Upload status: {upload_response.status_code}")
            
            if upload_response.status_code == 201:
                download_url = upload_response.json()['browser_download_url']
                logger.info(f"âœ… Backup uploadÃ© vers GitHub: {download_url}")
                
                # Nettoyage des anciennes releases
                self._cleanup_old_github_releases()
                
                return True
            else:
                logger.error(f"âŒ Erreur upload: {upload_response.status_code}")
                logger.error(f"ğŸ“‹ Response body: {upload_response.text}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erreur upload GitHub: {e}")
            import traceback
            logger.error(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
            return False
    
    def _create_release_description(self, backup_path):
        """CrÃ©e la description de la release"""
        try:
            # Charger les mÃ©tadonnÃ©es
            with zipfile.ZipFile(backup_path, 'r') as zipf:
                for file in zipf.namelist():
                    if file.endswith('_info.json'):
                        with zipf.open(file) as json_file:
                            metadata = json.load(json_file)
                            break
                else:
                    metadata = {}
            
            stats = metadata.get('database_stats', {})
            file_size_mb = round(os.path.getsize(backup_path) / (1024*1024), 2)
            
            return f"""# ğŸ­ Sauvegarde Automatique ERP DG Inc.

## ğŸ“‹ Informations
- **ğŸ“… Date:** {metadata.get('backup_time_readable', 'N/A')}
- **ğŸ“ Taille:** {file_size_mb} MB
- **ğŸ¢ Entreprise:** Desmarais & GagnÃ© Inc.

## ğŸ“Š Contenu de la Base
| Module | Enregistrements |
|--------|-----------------|
| Projets | {stats.get('projects', 0):,} |
| Entreprises | {stats.get('companies', 0):,} |
| EmployÃ©s | {stats.get('employees', 0):,} |
| Formulaires | {stats.get('formulaires', 0):,} |
| Postes Travail | {stats.get('work_centers', 0):,} |
| Pointages | {stats.get('time_entries', 0):,} |
| **TOTAL** | **{stats.get('total_records', 0):,}** |

## ğŸ“¦ Utilisation
1. TÃ©lÃ©charger le fichier ZIP
2. Extraire le contenu
3. Utiliser le fichier `.db` pour restaurer l'ERP

---
ğŸ¤– Sauvegarde automatique gÃ©nÃ©rÃ©e par le systÃ¨me corrigÃ©
"""
            
        except Exception as e:
            logger.error(f"Erreur crÃ©ation description: {e}")
            return f"""# ğŸ­ Sauvegarde ERP DG Inc.

**Date:** {datetime.now().strftime('%d/%m/%Y Ã  %H:%M:%S')}

Sauvegarde automatique de la base de donnÃ©es ERP Production.
"""
    
    def _cleanup_old_github_releases(self):
        """Supprime les anciennes releases de backup"""
        try:
            headers = {'Authorization': f'token {self.config["github_token"]}'}
            
            response = requests.get(
                f"{self.config['github_api_url']}/repos/{self.config['github_repo']}/releases",
                headers=headers,
                timeout=30
            )
            
            if response.status_code != 200:
                return
            
            releases = response.json()
            backup_releases = [r for r in releases if r['tag_name'].startswith('backup-')]
            backup_releases.sort(key=lambda x: x['created_at'], reverse=True)
            
            releases_to_delete = backup_releases[self.config['keep_github_releases']:]
            
            for release in releases_to_delete:
                delete_response = requests.delete(
                    f"{self.config['github_api_url']}/repos/{self.config['github_repo']}/releases/{release['id']}",
                    headers=headers,
                    timeout=30
                )
                
                if delete_response.status_code == 204:
                    logger.info(f"ğŸ—‘ï¸ Ancienne release supprimÃ©e: {release['tag_name']}")
                    
            if releases_to_delete:
                logger.info(f"ğŸ§¹ {len(releases_to_delete)} ancienne(s) release(s) supprimÃ©e(s)")
                
        except Exception as e:
            logger.error(f"Erreur nettoyage GitHub: {e}")
    
    def cleanup_old_backups(self):
        """Nettoie les anciennes sauvegardes locales"""
        try:
            backup_files = []
            for file in Path(self.config['backup_local_dir']).iterdir():
                if file.is_file() and file.suffix == '.zip':
                    backup_files.append((file, file.stat().st_mtime))
            
            backup_files.sort(key=lambda x: x[1], reverse=True)
            files_to_delete = backup_files[self.config['keep_local_backups']:]
            
            for file_path, _ in files_to_delete:
                file_path.unlink()
                logger.debug(f"ğŸ—‘ï¸ Fichier local supprimÃ©: {file_path}")
            
            if files_to_delete:
                logger.info(f"ğŸ§¹ {len(files_to_delete)} sauvegarde(s) locale(s) supprimÃ©e(s)")
                
        except Exception as e:
            logger.error(f"Erreur nettoyage local: {e}")
    
    def run_backup_cycle(self):
        """Cycle complet de sauvegarde - VERSION CORRIGÃ‰E"""
        logger.info("ğŸš€ ===== DÃ‰BUT CYCLE SAUVEGARDE GITHUB =====")
        
        try:
            # AMÃ‰LIORATION : Test de validitÃ© avant backup
            if not self.config['github_enabled']:
                logger.warning("âš ï¸ GitHub backup dÃ©sactivÃ© - cycle annulÃ©")
                return False
            
            # CrÃ©er backup
            backup_path = self.create_backup()
            
            if backup_path:
                logger.info(f"âœ… Backup crÃ©Ã©: {backup_path}")
                
                # Upload vers GitHub
                github_success = self.upload_to_github(backup_path)
                
                # Nettoyage
                self.cleanup_old_backups()
                
                if github_success:
                    logger.info("âœ… ===== CYCLE TERMINÃ‰ AVEC SUCCÃˆS =====")
                    return True
                else:
                    logger.warning("âš ï¸ ===== CYCLE TERMINÃ‰ AVEC AVERTISSEMENT =====")
                    logger.warning("   Backup local OK, GitHub KO")
                    return False
            else:
                logger.error("âŒ ===== CYCLE Ã‰CHOUÃ‰ =====")
                logger.error("   Impossible de crÃ©er la sauvegarde")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ===== ERREUR CYCLE =====")
            logger.error(f"   Exception: {e}")
            import traceback
            logger.error(f"   Traceback: {traceback.format_exc()}")
            return False

# Scheduler CORRIGÃ‰
def start_backup_scheduler():
    """Lance le scheduler GitHub backup - VERSION CORRIGÃ‰E"""
    try:
        backup_manager = GitHubBackupManager()
        
        # CORRECTION 1 : Utiliser les variables d'environnement
        schedule_minutes = backup_manager.config['backup_schedule_minutes']
        
        logger.info(f"â° Configuration scheduler:")
        logger.info(f"   ğŸ”„ FrÃ©quence: {schedule_minutes} minutes")
        logger.info(f"   ğŸ“¦ GitHub enabled: {backup_manager.config['github_enabled']}")
        logger.info(f"   ğŸ§ª Test immÃ©diat: {backup_manager.config['immediate_backup_test']}")
        logger.info(f"   ğŸš€ Force startup: {backup_manager.config['force_backup_on_start']}")
        
        # CORRECTION 2 : Programmer selon la variable d'environnement
        if schedule_minutes < 60:
            schedule.every(schedule_minutes).minutes.do(backup_manager.run_backup_cycle)
            logger.info(f"   ğŸ“… ProgrammÃ©: Toutes les {schedule_minutes} minutes")
        else:
            schedule.every(schedule_minutes // 60).hours.do(backup_manager.run_backup_cycle)
            logger.info(f"   ğŸ“… ProgrammÃ©: Toutes les {schedule_minutes // 60} heures")
        
        # CORRECTION 3 : Test immÃ©diat si demandÃ©
        if backup_manager.config['immediate_backup_test'] or backup_manager.config['force_backup_on_start']:
            logger.info("ğŸ§ª ExÃ©cution test immÃ©diat...")
            backup_manager.run_backup_cycle()
        
        # CORRECTION 4 : Boucle scheduler amÃ©liorÃ©e
        logger.info("ğŸ¯ Scheduler GitHub backup dÃ©marrÃ© !")
        
        while True:
            schedule.run_pending()
            time.sleep(30)  # VÃ©rifier toutes les 30 secondes
            
    except Exception as e:
        logger.error(f"âŒ Erreur scheduler GitHub: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")

# CORRECTION 5 : Configuration de dÃ©marrage amÃ©liorÃ©e
def setup_github_backup_info():
    """Affiche les informations de configuration au dÃ©marrage - VERSION CORRIGÃ‰E"""
    logger.info("ğŸš€ GITHUB RELEASES BACKUP SYSTEM - VERSION CORRIGÃ‰E")
    logger.info("=" * 60)
    
    # Variables de configuration
    config_vars = {
        'GITHUB_BACKUP_ENABLED': os.environ.get('GITHUB_BACKUP_ENABLED', 'NON DÃ‰FINI'),
        'GITHUB_TOKEN': 'âœ… ConfigurÃ©' if os.environ.get('GITHUB_TOKEN') else 'âŒ MANQUANT',
        'GITHUB_REPO': os.environ.get('GITHUB_REPO', 'NON DÃ‰FINI'),
        'KEEP_GITHUB_RELEASES': os.environ.get('KEEP_GITHUB_RELEASES', '10'),
        'BACKUP_SCHEDULE_MINUTES': os.environ.get('BACKUP_SCHEDULE_MINUTES', '120'),
        'IMMEDIATE_BACKUP_TEST': os.environ.get('IMMEDIATE_BACKUP_TEST', 'false'),
        'FORCE_BACKUP_ON_START': os.environ.get('FORCE_BACKUP_ON_START', 'false'),
        'DEBUG_GITHUB_BACKUP': os.environ.get('DEBUG_GITHUB_BACKUP', 'false')
    }
    
    logger.info("ğŸ“‹ Configuration complÃ¨te:")
    for var, value in config_vars.items():
        logger.info(f"   {var}: {value}")
    
    if not os.environ.get('GITHUB_TOKEN'):
        logger.error("ğŸš¨ CONFIGURATION REQUISE:")
        logger.error("   1. CrÃ©er Personal Access Token sur GitHub")
        logger.error("   2. Ajouter GITHUB_TOKEN sur Render")
        logger.error("   3. RedÃ©marrer le service")

# CORRECTION 6 : Auto-start amÃ©liorÃ©
if __name__ != "__main__":  # Quand importÃ© par app.py
    # Afficher les infos de configuration
    setup_github_backup_info()
    
    # CORRECTION MAJEURE : Thread NON daemon pour persistence
    backup_thread = threading.Thread(target=start_backup_scheduler, daemon=False)
    backup_thread.start()
    
    logger.info("ğŸ¯ GitHub Backup System CORRIGÃ‰ dÃ©marrÃ© !")

# NOUVEAU : Fonction de test direct
def test_backup_immediate():
    """Fonction de test pour backup immÃ©diat"""
    logger.info("ğŸ§ª TEST BACKUP IMMÃ‰DIAT")
    backup_manager = GitHubBackupManager()
    result = backup_manager.run_backup_cycle()
    logger.info(f"ğŸ RÃ©sultat test: {'âœ… SUCCÃˆS' if result else 'âŒ Ã‰CHEC'}")
    return result

if __name__ == "__main__":
    # Test direct
    logger.info("ğŸ§ª Mode test GitHub backup")
    setup_github_backup_info()
    test_backup_immediate()
